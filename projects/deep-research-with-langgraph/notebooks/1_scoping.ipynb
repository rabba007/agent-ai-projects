{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and set up auto-reload\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf3150",
   "metadata": {},
   "source": [
    "## User Clarification and Brief Generation\n",
    "\n",
    "The goal of scoping is to gather user-context needed for research.\n",
    "\n",
    "### Overall Flow\n",
    "\n",
    "<img src=\"./assets/overall_flow.png\" width=1200>\n",
    "\n",
    "\n",
    "We shall scope the research in two phases:\n",
    "\n",
    "1. User Clarification : Determines if additional clarification is needed from the user\n",
    "2. Brief Generation : Transforms the conversation into a detailed  research brief\n",
    "\n",
    "<img src=\"./assets/scoping_flow.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_prompt\n",
    "from deep_research_with_langgraph.prompts import clarify_with_user_instructions\n",
    "show_prompt(clarify_with_user_instructions, \"Clarify with User Instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dfe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/deep_research_with_langgraph/state_scope.py\n",
    "\n",
    "\"\"\"State Definitions and Pydantic Schemas for Research Scoping.\n",
    "\n",
    "This defines the state objects and structured schemas used for\n",
    "the research agent scoping workflow, including researcher state management and output schemas.\n",
    "\"\"\"\n",
    "\n",
    "import operator\n",
    "from typing_extensions import Optional, Annotated, List, Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# ===== STATE DEFINITIONS =====\n",
    "\n",
    "class AgentInputState(MessagesState):\n",
    "    \"\"\"Input state for the full agent - only contains messages from user input.\"\"\"\n",
    "    pass\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"\n",
    "    Main state for the full multi-agent research system.\n",
    "    \n",
    "    Extends MessagesState with additional fields for research coordination.\n",
    "    Note: Some fields are duplicated across different state classes for proper\n",
    "    state management between subgraphs and the main workflow.\n",
    "    \"\"\"\n",
    "\n",
    "    # Research brief generated from user conversation history\n",
    "    research_brief: Optional[str]\n",
    "    # Messages exchanged with the supervisor agent for coordination\n",
    "    supervisor_messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    # Raw unprocessed research notes collected during the research phase\n",
    "    raw_notes: Annotated[list[str], operator.add] = []\n",
    "    # Processed and structured notes ready for report generation\n",
    "    notes: Annotated[list[str], operator.add] = []\n",
    "    # Final formatted research report\n",
    "    final_report: str\n",
    "\n",
    "\n",
    "# ===== STRUCTURED OUTPUT SCHEMAS =====\n",
    "\n",
    "class ClarifyWithUser(BaseModel):\n",
    "    \"\"\"Schema for user clarification decision and questions.\"\"\"\n",
    "    \n",
    "    need_clarification: bool = Field(\n",
    "        description=\"Whether the user needs to be asked a clarifying question.\",\n",
    "    )\n",
    "    question: str = Field(\n",
    "        description=\"A question to ask the user to clarify the report scope\",\n",
    "    )\n",
    "    verification: str = Field(\n",
    "        description=\"Verify message that we will start research after the user has provided the necessary information.\",\n",
    "    )\n",
    "\n",
    "class ResearchQuestion(BaseModel):\n",
    "    \"\"\"Schema for structured research brief generation.\"\"\"\n",
    "    \n",
    "    research_brief: str = Field(\n",
    "        description=\"A research question that will be used to guide the research.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/deep_research_with_langgraph/research_agent_scope.py\n",
    "\n",
    "\"\"\"User Clarification and Research Brief Generation.\n",
    "\n",
    "This module implements the scoping phase of the research workflow, where we:\n",
    "1. Assess if the user's request needs clarification\n",
    "2. Generate a detailed research brief from the conversation\n",
    "\n",
    "The workflow uses structured output to make deterministic decisions about\n",
    "whether sufficient context exists to proceed with research.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessage, get_buffer_string\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "\n",
    "from deep_research_with_langgraph.prompts import clarify_with_user_instructions,transform_messages_into_research_topic_prompt\n",
    "from deep_research_with_langgraph.state_scope import AgentState, ClarifyWithUser, ResearchQuestion, AgentInputState\n",
    "\n",
    "# ===== UTILITY FUNCTIONS =====\n",
    "\n",
    "def get_today_str() -> str:\n",
    "    \"\"\"Get current date in a human-readable format.\"\"\"\n",
    "    return datetime.now().strftime(\"%a %b %-d, %Y\")\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "\n",
    "# Initialize model\n",
    "model_gemini_flash = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", timeout=30, temperature=0)\n",
    "model_llama_groq = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\", timeout=30, temperature=0)\n",
    "model = model_gemini_flash\n",
    "\n",
    "\n",
    "# ===== WORKFLOW NODES =====\n",
    "\n",
    "def clarify_with_user(state: AgentState) -> Command[Literal[\"write_research_brief\", \"__end__\"]]:\n",
    "    \"\"\"\n",
    "    Determine if the user's request contains sufficient information to proceed with research.\n",
    "    \n",
    "    Uses structured output to make deterministic decisions and avoid hallucination.\n",
    "    Routes to either research brief generation or ends with a clarification question.\n",
    "    \"\"\"\n",
    "    # Set up structured output model\n",
    "    structured_output_model = model.with_structured_output(ClarifyWithUser)\n",
    "\n",
    "    # Invoke the model with clarification instructions\n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=clarify_with_user_instructions.format(\n",
    "            messages=get_buffer_string(messages=state[\"messages\"]), \n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Route based on clarification need\n",
    "    if response.need_clarification:\n",
    "        return Command(\n",
    "            goto=END, \n",
    "            update={\"messages\": [AIMessage(content=response.question)]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"write_research_brief\", \n",
    "            update={\"messages\": [AIMessage(content=response.verification)]}\n",
    "        )\n",
    "\n",
    "def write_research_brief(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transform the conversation history into a comprehensive research brief.\n",
    "    \n",
    "    Uses structured output to ensure the brief follows the required format\n",
    "    and contains all necessary details for effective research.\n",
    "    \"\"\"\n",
    "    # Set up structured output model\n",
    "    structured_output_model = model.with_structured_output(ResearchQuestion)\n",
    "    \n",
    "    # Generate research brief from conversation history\n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=transform_messages_into_research_topic_prompt.format(\n",
    "            messages=get_buffer_string(state.get(\"messages\", [])),\n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Update state with generated research brief and pass it to the supervisor\n",
    "    return {\n",
    "        \"research_brief\": response.research_brief,\n",
    "        \"supervisor_messages\": [HumanMessage(content=f\"{response.research_brief}.\")]\n",
    "    }\n",
    "\n",
    "\n",
    "# ===== GRAPH CONSTRUCTION =====\n",
    "\n",
    "# Build the scoping workflow\n",
    "deep_researcher_builder = StateGraph(AgentState, input_schema=AgentInputState)\n",
    "\n",
    "# Add workflow nodes\n",
    "deep_researcher_builder.add_node(\"clarify_with_user\", clarify_with_user)\n",
    "deep_researcher_builder.add_node(\"write_research_brief\", write_research_brief)\n",
    "\n",
    "# Add workflow edges\n",
    "deep_researcher_builder.add_edge(START, \"clarify_with_user\")\n",
    "deep_researcher_builder.add_edge(\"write_research_brief\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "scope_research = deep_researcher_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed734997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with in-memory checkpointer to test in notebook\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from deep_research_with_langgraph.research_agent_scope import deep_researcher_builder\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "scope = deep_researcher_builder.compile(checkpointer=checkpointer)\n",
    "display(Image(scope.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow\n",
    "from utils import format_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "#result = scope.invoke({\"messages\": [HumanMessage(content=\"I want to research the best coffee shops in San Francisco.\")]}, config=thread)\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd548ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = scope.invoke({\"messages\": [HumanMessage(content=\"Let's examine coffee quality to assess the best coffee shops in San Francisco.\")]}, config=thread)\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5031b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(result[\"research_brief\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c69dd",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b472132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "conversation_1 = [\n",
    "    HumanMessage(content=\"What's the best way to invest $50,000 for retirement?\"),\n",
    "    AIMessage(content=\"Could you please provide some additional information to tailor the investment advice for your $50,000 retirement goal? Specifically:\\n Your current age or desired retirement age\\n Your risk tolerance (low, medium, high)\\n Any preferences for investment types (e.g., stocks, bonds, mutual funds, real estate)\\n Whether you are investing through a tax-advantaged account (e.g., IRA, 401(k)) or a regular brokerage account\\n This will help me provide more personalized and relevant suggestions.\"),\n",
    "    HumanMessage(content=\"I'm 25 and I want to retire by 45. My risk tolerance is high right now but I think will decrease over time. I have heard that stocks and ETFs are a good choice, but I'm open to anything. And I already have a 401k, but this would just be through a regular brokerage account.\"),\n",
    "]\n",
    "\n",
    "conversation_2 = [\n",
    "    HumanMessage(content=\"I am looking for an apartment in NYC, can you help me?\"),\n",
    "    AIMessage(content=\"Could you please specify your apartment preferences? For example:\\n Desired neighborhoods or boroughs\\n Number of bedrooms/bathrooms\\n Budget range (monthly rent)\\n Any amenities or must-have features\\n Preferred move-in date\\n This information will help me provide the most relevant apartment options in NYC.\"),\n",
    "    HumanMessage(content=\"I'd prefer to live in Chelsea, Flatiron, or West Village. I'm looking for a 2 bed 2 bath, and I am looking for monthly rent below 7k. I'd like this to be a doorman building and have an in unit washer and dryer, but it's okay if there's no washer dryer. It's a plus if the building has a gym. And I'd like to move in in Feb 2026.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d119add",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_1 = [\n",
    "    \"Current age is 25\",\n",
    "    \"Desired retirement age is 45\",\n",
    "    \"Current risk tolerance is high\",\n",
    "    \"Interested in investing in stocks and ETFs\",\n",
    "    \"Open to forms of investment beyond stocks and ETFs\"\n",
    "    \"Investment account is a regular brokerage account\",\n",
    "]\n",
    "\n",
    "criteria_2 = [\n",
    "    \"Looking for a 2 bed 2 bath apartment in Chelsea, Flatiron, or West Village\",\n",
    "    \"Monthly rent below 7k\",\n",
    "    \"Should be in a doorman building\",\n",
    "    \"Ideally have an in unit washer and dryer but not strict\",\n",
    "    \"Ideally have a gym but not strict\",\n",
    "    \"Move in date is Feb 2026\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langsmith import Client\n",
    "\n",
    "# Initialize the LangSmith client\n",
    "langsmith_client = Client(api_key=os.getenv(\"LANGSMITH_API_KEY\"))\n",
    "\n",
    "# Create the dataset\n",
    "dataset_name = \"deep_research_scoping\"\n",
    "if not langsmith_client.has_dataset(dataset_name=dataset_name):\n",
    "    \n",
    "    # Create the dataset\n",
    "    dataset = langsmith_client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"A dataset that measures the quality of research briefs generated from an input conversation\",\n",
    "    )\n",
    "\n",
    "    # Add the examples to the dataset\n",
    "    langsmith_client.create_examples(\n",
    "        dataset_id=dataset.id,\n",
    "        examples=[\n",
    "            {\n",
    "                \"inputs\": {\"messages\": conversation_1},\n",
    "                \"outputs\": {\"criteria\": criteria_1},\n",
    "            },\n",
    "            {\n",
    "                \"inputs\": {\"messages\": conversation_2},\n",
    "                \"outputs\": {\"criteria\": criteria_2},\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b59035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_research_with_langgraph.prompts import BRIEF_CRITERIA_PROMPT\n",
    "show_prompt(BRIEF_CRITERIA_PROMPT, \"BRIEF_CRITERIA_PROMPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langsmith.evaluation import EvaluationResult\n",
    "from typing_extensions import cast\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Criteria(BaseModel):\n",
    "    \"\"\"\n",
    "    Individual success criteria evaluation result.\n",
    "    \n",
    "    This model represents a single evaluation criteria that should be present\n",
    "    in the research brief, along with a detailed assessment of whether it was\n",
    "    successfully captured and the reasoning behind that assessment.\n",
    "    \"\"\"\n",
    "    criteria_text: str = Field(\n",
    "        description=\"The specific success criteria being evaluated (e.g., 'Current age is 25', 'Monthly rent below 7k')\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Detailed explanation of why this criteria is or isn't captured in the research brief, including specific evidence from the brief\"\n",
    "    )\n",
    "    is_captured: bool = Field(\n",
    "        description=\"Whether this specific criteria is adequately captured in the research brief (True) or missing/inadequately addressed (False)\"\n",
    "    )\n",
    "\n",
    "def evaluate_success_criteria(outputs: dict, reference_outputs: dict):\n",
    "    \"\"\"\n",
    "    Evaluate whether the research brief captures all required success criteria.\n",
    "    \n",
    "    This function evaluates each criterion individually to provide focused assessment\n",
    "    and detailed reasoning for each evaluation decision.\n",
    "    \n",
    "    Args:\n",
    "        outputs: Dictionary containing the research brief to evaluate\n",
    "        reference_outputs: Dictionary containing the list of success criteria\n",
    "        \n",
    "    Returns:\n",
    "        Dict with evaluation results including score (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    research_brief = outputs[\"research_brief\"]\n",
    "    success_criteria = reference_outputs[\"criteria\"]\n",
    "\n",
    "    #model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "    model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", timeout=30, temperature=0)\n",
    "    structured_output_model = model.with_structured_output(Criteria)\n",
    "    \n",
    "    # Run evals\n",
    "    responses = structured_output_model.batch([\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=BRIEF_CRITERIA_PROMPT.format(\n",
    "                research_brief=research_brief,\n",
    "                criterion=criterion\n",
    "            )\n",
    "        )\n",
    "    ] \n",
    "    for criterion in success_criteria])\n",
    "    \n",
    "    # Ensure the criteria_text field is populated correctly\n",
    "    individual_evaluations = [\n",
    "        {\n",
    "            \"criteria\":criterion,\n",
    "            \"captured\": response.is_captured,\n",
    "            \"reasoning\": response.reasoning\n",
    "        }\n",
    "        for criterion, response in zip(success_criteria, responses)\n",
    "    ]\n",
    "    \n",
    "    # Calculate overall score as percentage of captured criteria\n",
    "    captured_count = sum(1 for eval_result in individual_evaluations if eval_result['captured'])\n",
    "    total_count = len(individual_evaluations)\n",
    "    \n",
    "    return {\n",
    "        \"key\": \"success_criteria_score\", \n",
    "        \"score\": captured_count / total_count if total_count > 0 else 0.0,\n",
    "        \"comment\" :f\"Captured {captured_count}/{total_count} criteria. Details: {individual_evaluations}\"\n",
    "        }\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_research_with_langgraph.prompts import BRIEF_HALLUCINATION_PROMPT\n",
    "show_prompt(BRIEF_HALLUCINATION_PROMPT, \"BRIEF_HALLUCINATION_PROMPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved NoAssumptions class with reasoning field and enhanced descriptions\n",
    "\n",
    "\n",
    "class NoAssumptions(BaseModel):\n",
    "    \"\"\"\n",
    "    Evaluation model for checking if research brief makes unwarranted assumptions.\n",
    "    \n",
    "    This model evaluates whether the research brief contains any assumptions,\n",
    "    inferences, or additions that were not explicitly stated by the user in their\n",
    "    original conversation. It provides detailed reasoning for the evaluation decision.\n",
    "    \"\"\"\n",
    "    no_assumptions: bool = Field(\n",
    "        description=\"Whether the research brief avoids making unwarranted assumptions. True if the brief only includes information explicitly provided by the user, False if it makes assumptions beyond what was stated.\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Detailed explanation of the evaluation decision, including specific examples of any assumptions found or confirmation that no assumptions were made beyond the user's explicit statements.\"\n",
    "    )\n",
    "\n",
    "def evaluate_no_assumptions(outputs: dict, reference_outputs: dict):\n",
    "    \"\"\"\n",
    "    Evaluate whether the research brief avoids making unwarranted assumptions.\n",
    "    \n",
    "    This evaluator checks that the research brief only includes information\n",
    "    and requirements that were explicitly provided by the user, without\n",
    "    making assumptions about unstated preferences or requirements.\n",
    "    \n",
    "    Args:\n",
    "        outputs: Dictionary containing the research brief to evaluate\n",
    "        reference_outputs: Dictionary containing the success criteria for reference\n",
    "        \n",
    "    Returns:\n",
    "        Dict with evaluation results including boolean score and detailed reasoning\n",
    "    \"\"\"\n",
    "    research_brief = outputs[\"research_brief\"]\n",
    "    success_criteria = reference_outputs[\"criteria\"]\n",
    "    \n",
    "    #model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "    model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", timeout=30, temperature=0)\n",
    "    structured_output_model = model.with_structured_output(NoAssumptions)\n",
    "    \n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=BRIEF_HALLUCINATION_PROMPT.format(\n",
    "            research_brief=research_brief, \n",
    "            success_criteria=str(success_criteria)\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"key\": \"no_assumptions_score\", \n",
    "        \"score\": response.no_assumptions,\n",
    "        \"comment\": f\"Reasoning : {response.reasoning}\"\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e425ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def target_func(inputs: dict):\n",
    "    config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "    return scope.invoke(inputs, config=config)\n",
    "\n",
    "langsmith_client.evaluate(\n",
    "    target_func,\n",
    "    data=dataset_name,\n",
    "    evaluators=[evaluate_success_criteria, evaluate_no_assumptions],\n",
    "    experiment_prefix=\"Deep Research Scoping-After Fix\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b9726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
