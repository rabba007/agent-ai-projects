{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee274760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c1f8b5",
   "metadata": {},
   "source": [
    "## Research Agent\n",
    "\n",
    "The goal of research is to gather the context requested by the research brief.\n",
    "\n",
    "Here is the overall research flow :\n",
    "\n",
    "<img src=\"./assets/overall_flow.png\" width=800/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb360b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_prompt\n",
    "from deep_research_with_langgraph.prompts import research_agent_prompt\n",
    "show_prompt(research_agent_prompt, \"Research Agent Instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8682221",
   "metadata": {},
   "source": [
    "### State and Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/deep_research_with_langgraph/state_research.py\n",
    "\n",
    "\"\"\"\n",
    "State Definitions and Pydantic Schemas for Research Agent\n",
    "\n",
    "This module defines the state objects and structured schemas used for\n",
    "the research agent workflow, including researcher state management and output schemas.\n",
    "\"\"\"\n",
    "\n",
    "import operator\n",
    "from typing_extensions import TypedDict, Annotated, List, Sequence\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# ===== STATE DEFINITIONS =====\n",
    "\n",
    "class ResearcherState(TypedDict):\n",
    "    \"\"\"\n",
    "    State for the research agent containing message history and research metadata.\n",
    "    \n",
    "    This state tracks the researcher's conversation, iteration count for limiting\n",
    "    tool calls, the research topic being investigated, compressed findings,\n",
    "    and raw research notes for detailed analysis.\n",
    "    \"\"\"\n",
    "    researcher_messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    tool_call_iterations: int\n",
    "    research_topic: str\n",
    "    compressed_research: str\n",
    "    raw_notes: Annotated[List[str], operator.add]\n",
    "\n",
    "class ResearcherOutputState(TypedDict):\n",
    "    \"\"\"\n",
    "    Output state for the research agent containing final research results.\n",
    "    \n",
    "    This represents the final output of the research process with compressed\n",
    "    research findings and all raw notes from the research process.\n",
    "    \"\"\"\n",
    "    compressed_research: str\n",
    "    raw_notes: Annotated[List[str], operator.add]\n",
    "    researcher_messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "# ===== STRUCTURED OUTPUT SCHEMAS =====\n",
    "\n",
    "class ClarifyWithUser(BaseModel):\n",
    "    \"\"\"Schema for user clarification decisions during scoping phase.\"\"\"\n",
    "    need_clarification: bool = Field(\n",
    "        description=\"Whether the user needs to be asked a clarifying question.\",\n",
    "    )\n",
    "    question: str = Field(\n",
    "        description=\"A question to ask the user to clarify the report scope\",\n",
    "    )\n",
    "    verification: str = Field(\n",
    "        description=\"Verify message that we will start research after the user has provided the necessary information.\",\n",
    "    )\n",
    "\n",
    "class ResearchQuestion(BaseModel):\n",
    "    \"\"\"Schema for research brief generation.\"\"\"\n",
    "    research_brief: str = Field(\n",
    "        description=\"A research question that will be used to guide the research.\",\n",
    "    )\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"Schema for webpage content summarization.\"\"\"\n",
    "    summary: str = Field(description=\"Concise summary of the webpage content\")\n",
    "    key_excerpts: str = Field(description=\"Important quotes and excerpts from the content\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/deep_research_with_langgraph/utils.py\n",
    "\n",
    "from datetime import datetime\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import Annotated, List, Literal\n",
    "from langchain.chat_models import init_chat_model\n",
    "from tavily import TavilyClient\n",
    "from deep_research_with_langgraph.state_research import Summary\n",
    "from deep_research_with_langgraph.prompts import summarize_webpage_prompt\n",
    "from langchain_core.tools import tool, InjectedToolArg\n",
    "\n",
    "\"\"\"Research Utilities and Tools.\n",
    "\n",
    "This module provides search and content processing utilities for the research agent,\n",
    "including web search capabilities and content summarization tools.\n",
    "\"\"\"\n",
    "# ===== UTILITY FUNCTIONS =====\n",
    "\n",
    "def get_today_str() -> str:\n",
    "    \"\"\"Get current date in a human-readable format.\"\"\"\n",
    "    return datetime.now().strftime(\"%a %b %-d, %Y\")\n",
    "\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "\n",
    "summarization_model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\", timeout=30, temperature=0)\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "# ===== SEARCH FUNCTIONS =====\n",
    "\n",
    "def tavily_search_multiple(\n",
    "    search_queries: List[str], \n",
    "    max_results: int = 3, \n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\", \n",
    "    include_raw_content: bool = True, \n",
    ") -> List[dict]:\n",
    "    \"\"\"Perform search using Tavily API for multiple queries.\n",
    "\n",
    "    Args:\n",
    "        search_queries: List of search queries to execute\n",
    "        max_results: Maximum number of results per query\n",
    "        topic: Topic filter for search results\n",
    "        include_raw_content: Whether to include raw webpage content\n",
    "\n",
    "    Returns:\n",
    "        List of search result dictionaries\n",
    "    \"\"\"\n",
    "    # Execute searches sequentially. Note: yon can use AsyncTavilyClient to parallelize this step.\n",
    "    search_docs = []\n",
    "    for query in search_queries:\n",
    "        result = tavily_client.search(\n",
    "            query,\n",
    "            max_results=max_results,\n",
    "            include_raw_content=include_raw_content,\n",
    "            topic=topic\n",
    "        )\n",
    "        search_docs.append(result)\n",
    "\n",
    "    return search_docs\n",
    "\n",
    "def summarize_webpage_content(webpage_content: str) -> str:\n",
    "    \"\"\"Summarize webpage content using the configured summarization model.\n",
    "    \n",
    "    Args:\n",
    "        webpage_content: Raw webpage content to summarize\n",
    "        \n",
    "    Returns:\n",
    "        Formatted summary with key excerpts\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Set up structured output model for summarization\n",
    "        structured_model = summarization_model.with_structured_output(Summary)\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = structured_model.invoke([\n",
    "            HumanMessage(content=summarize_webpage_prompt.format(\n",
    "                webpage_content=webpage_content, \n",
    "                date=get_today_str()\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Format summary with clear structure\n",
    "        formatted_summary = (\n",
    "            f\"<summary>\\n{summary.summary}\\n</summary>\\n\\n\"\n",
    "            f\"<key_excerpts>\\n{summary.key_excerpts}\\n</key_excerpts>\"\n",
    "        )\n",
    "        \n",
    "        return formatted_summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to summarize webpage: {str(e)}\")\n",
    "        return webpage_content[:1000] + \"...\" if len(webpage_content) > 1000 else webpage_content\n",
    "\n",
    "def deduplicate_search_results(search_results: List[dict]) -> dict:\n",
    "    \"\"\"Deduplicate search results by URL to avoid processing duplicate content.\n",
    "    \n",
    "    Args:\n",
    "        search_results: List of search result dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping URLs to unique results\n",
    "    \"\"\"\n",
    "    unique_results = {}\n",
    "    \n",
    "    for response in search_results:\n",
    "        for result in response['results']:\n",
    "            url = result['url']\n",
    "            if url not in unique_results:\n",
    "                unique_results[url] = result\n",
    "    \n",
    "    return unique_results\n",
    "\n",
    "def process_search_results(unique_results: dict) -> dict:\n",
    "    \"\"\"Process search results by summarizing content where available.\n",
    "    \n",
    "    Args:\n",
    "        unique_results: Dictionary of unique search results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of processed results with summaries\n",
    "    \"\"\"\n",
    "    summarized_results = {}\n",
    "    \n",
    "    for url, result in unique_results.items():\n",
    "        # Use existing content if no raw content for summarization\n",
    "        if not result.get(\"raw_content\"):\n",
    "            content = result['content']\n",
    "        else:\n",
    "            # Summarize raw content for better processing\n",
    "            content = summarize_webpage_content(result['raw_content'])\n",
    "        \n",
    "        summarized_results[url] = {\n",
    "            'title': result['title'],\n",
    "            'content': content\n",
    "        }\n",
    "    \n",
    "    return summarized_results\n",
    "\n",
    "\n",
    "def format_search_output(summarized_results: dict) -> str:\n",
    "    \"\"\"Format search results into a well-structured string output.\n",
    "    \n",
    "    Args:\n",
    "        summarized_results: Dictionary of processed search results\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string of search results with clear source separation\n",
    "    \"\"\"\n",
    "    if not summarized_results:\n",
    "        return \"No valid search results found. Please try different search queries or use a different search API.\"\n",
    "    \n",
    "    formatted_output = \"Search results: \\n\\n\"\n",
    "    \n",
    "    for i, (url, result) in enumerate(summarized_results.items(), 1):\n",
    "        formatted_output += f\"\\n\\n--- SOURCE {i}: {result['title']} ---\\n\"\n",
    "        formatted_output += f\"URL: {url}\\n\\n\"\n",
    "        formatted_output += f\"SUMMARY:\\n{result['content']}\\n\\n\"\n",
    "        formatted_output += \"-\" * 80 + \"\\n\"\n",
    "    \n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "# ===== RESEARCH TOOLS =====\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def tavily_search(\n",
    "    query: str,\n",
    "    max_results: Annotated[int, InjectedToolArg] = 3,\n",
    "    topic: Annotated[Literal[\"general\", \"news\", \"finance\"], InjectedToolArg] = \"general\",\n",
    ") -> str:\n",
    "    \"\"\"Fetch results from Tavily search API with content summarization.\n",
    "\n",
    "    Args:\n",
    "        query: A single search query to execute\n",
    "        max_results: Maximum number of results to return\n",
    "        topic: Topic to filter results by ('general', 'news', 'finance')\n",
    "\n",
    "    Returns:\n",
    "        Formatted string of search results with summaries\n",
    "    \"\"\"\n",
    "    # Execute search for single query\n",
    "    search_results = tavily_search_multiple(\n",
    "        [query],  # Convert single query to list for the internal function\n",
    "        max_results=max_results,\n",
    "        topic=topic,\n",
    "        include_raw_content=True,\n",
    "    )\n",
    "\n",
    "    # Deduplicate results by URL to avoid processing duplicate content\n",
    "    unique_results = deduplicate_search_results(search_results)\n",
    "\n",
    "    # Process results with summarization\n",
    "    summarized_results = process_search_results(unique_results)\n",
    "\n",
    "    # Format output for consumption\n",
    "    return format_search_output(summarized_results)\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def think_tool(reflection: str) -> str:\n",
    "    \"\"\"Tool for strategic reflection on research progress and decision-making.\n",
    "    \n",
    "    Use this tool after each search to analyze results and plan next steps systematically.\n",
    "    This creates a deliberate pause in the research workflow for quality decision-making.\n",
    "    \n",
    "    When to use:\n",
    "    - After receiving search results: What key information did I find?\n",
    "    - Before deciding next steps: Do I have enough to answer comprehensively?\n",
    "    - When assessing research gaps: What specific information am I still missing?\n",
    "    - Before concluding research: Can I provide a complete answer now?\n",
    "    \n",
    "    Reflection should address:\n",
    "    1. Analysis of current findings - What concrete information have I gathered?\n",
    "    2. Gap assessment - What crucial information is still missing?\n",
    "    3. Quality evaluation - Do I have sufficient evidence/examples for a good answer?\n",
    "    4. Strategic decision - Should I continue searching or provide my answer?\n",
    "    \n",
    "    Args:\n",
    "        reflection: Your detailed reflection on research progress, findings, gaps, and next steps\n",
    "        \n",
    "    Returns:\n",
    "        Confirmation that reflection was recorded for decision-making\n",
    "    \"\"\"\n",
    "    return f\"Reflection recorded: {reflection}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d52c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/deep_research_with_langgraph/research_agent.py\n",
    "\n",
    "\"\"\"Research Agent Implementation.\n",
    "\n",
    "This module implements a research agent that can perform iterative web searches\n",
    "and synthesis to answer complex research questions.\n",
    "\"\"\"\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from typing_extensions import Literal\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, filter_messages\n",
    "from deep_research_with_langgraph.utils import tavily_search, think_tool,get_today_str\n",
    "from deep_research_with_langgraph.prompts import research_agent_prompt,compress_research_system_prompt,compress_research_human_message\n",
    "from deep_research_with_langgraph.state_research import ResearcherState,ResearcherOutputState\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "\n",
    "# Set up tools and model binding\n",
    "tools = [tavily_search, think_tool]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize models\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\" ,timeout=30, temperature=0)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "summarization_model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", timeout=30, temperature=0)\n",
    "compress_model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", timeout=30, temperature=0,max_tokens=32000)\n",
    "\n",
    "# ===== AGENT NODES =====\n",
    "\n",
    "def llm_call(state: ResearcherState):\n",
    "    \"\"\"Analyze current state and decide on next actions.\n",
    "    \n",
    "    The model analyzes the current conversation state and decides whether to:\n",
    "    1. Call search tools to gather more information\n",
    "    2. Provide a final answer based on gathered information\n",
    "    \n",
    "    Returns updated state with the model's response.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"researcher_messages\": [\n",
    "            model_with_tools.invoke(\n",
    "                [SystemMessage(content=research_agent_prompt)] + state[\"researcher_messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def tool_node(state: ResearcherState):\n",
    "    \"\"\"Execute all tool calls from the previous LLM response.\n",
    "    \n",
    "    Executes all tool calls from the previous LLM responses.\n",
    "    Returns updated state with tool execution results.\n",
    "    \"\"\"\n",
    "    tool_calls = state[\"researcher_messages\"][-1].tool_calls\n",
    " \n",
    "    # Execute all tool calls\n",
    "    observations = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observations.append(tool.invoke(tool_call[\"args\"]))\n",
    "            \n",
    "    # Create tool message outputs\n",
    "    tool_outputs = [\n",
    "        ToolMessage(\n",
    "            content=observation,\n",
    "            name=tool_call[\"name\"],\n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        ) for observation, tool_call in zip(observations, tool_calls)\n",
    "    ]\n",
    "    \n",
    "    return {\"researcher_messages\": tool_outputs}\n",
    "\n",
    "def compress_research(state: ResearcherState) -> dict:\n",
    "    \"\"\"Compress research findings into a concise summary.\n",
    "    \n",
    "    Takes all the research messages and tool outputs and creates\n",
    "    a compressed summary suitable for the supervisor's decision-making.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = compress_research_system_prompt.format(date=get_today_str())\n",
    "    messages = [SystemMessage(content=system_message)] + state.get(\"researcher_messages\", []) + [HumanMessage(content=compress_research_human_message)]\n",
    "    response = compress_model.invoke(messages)\n",
    "    \n",
    "    # Extract raw notes from tool and AI messages\n",
    "    raw_notes = [\n",
    "        str(m.content) for m in filter_messages(\n",
    "            state[\"researcher_messages\"], \n",
    "            include_types=[\"tool\", \"ai\"]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"compressed_research\": str(response.content),\n",
    "        \"raw_notes\": [\"\\n\".join(raw_notes)]\n",
    "    }\n",
    "\n",
    "# ===== ROUTING LOGIC =====\n",
    "\n",
    "def should_continue(state: ResearcherState) -> Literal[\"tool_node\", \"compress_research\"]:\n",
    "    \"\"\"Determine whether to continue research or provide final answer.\n",
    "    \n",
    "    Determines whether the agent should continue the research loop or provide\n",
    "    a final answer based on whether the LLM made tool calls.\n",
    "    \n",
    "    Returns:\n",
    "        \"tool_node\": Continue to tool execution\n",
    "        \"compress_research\": Stop and compress research\n",
    "    \"\"\"\n",
    "    messages = state[\"researcher_messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the LLM makes a tool call, continue to tool execution\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    # Otherwise, we have a final answer\n",
    "    return \"compress_research\"\n",
    "\n",
    "# ===== GRAPH CONSTRUCTION =====\n",
    "\n",
    "# Build the agent workflow\n",
    "agent_builder = StateGraph(ResearcherState, output_schema=ResearcherOutputState)\n",
    "# Add nodes to the graph\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "agent_builder.add_node(\"compress_research\", compress_research)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_node\": \"tool_node\", # Continue research loop\n",
    "        \"compress_research\": \"compress_research\", # Provide final answer\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"tool_node\",\"llm_call\")\n",
    "agent_builder.add_edge(\"compress_research\", END)\n",
    "\n",
    "# Compile the agent\n",
    "researcher_agent = agent_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cc853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from deep_research_with_langgraph.research_agent import researcher_agent\n",
    "\n",
    "# Show the agent\n",
    "display(Image(researcher_agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3908cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent\n",
    "from utils import format_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Example brief\n",
    "research_brief = \"\"\"I want to identify and evaluate the coffee shops in San Francisco that are considered the best based specifically  \n",
    "on coffee quality. My research should focus on analyzing and comparing coffee shops within the San Francisco area, \n",
    "using coffee quality as the primary criterion. I am open regarding methods of assessing coffee quality (e.g.,      \n",
    "expert reviews, customer ratings, specialty coffee certifications), and there are no constraints on ambiance,      \n",
    "location, wifi, or food options unless they directly impact perceived coffee quality. Please prioritize primary    \n",
    "sources such as the official websites of coffee shops, reputable third-party coffee review organizations (like     \n",
    "Coffee Review or Specialty Coffee Association), and prominent review aggregators like Google or Yelp where direct  \n",
    "customer feedback about coffee quality can be found. The study should result in a well-supported list or ranking of\n",
    "the top coffee shops in San Francisco, emphasizing their coffee quality according to the latest available data as  \n",
    "of Dec 2025.\"\"\"\n",
    "\n",
    "#result = researcher_agent.invoke({\"researcher_messages\": [HumanMessage(content=f\"{research_brief}.\")]})\n",
    "format_messages(result['researcher_messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed46a07",
   "metadata": {},
   "source": [
    "### Evals\n",
    "\n",
    "Agents use a self-directed trajectory of tool calls to accomplish tasks.\n",
    "\n",
    "Let's think about the ramifications of a poorly tuned tool-calling loop:\n",
    "-  Early Termination: The agent decides to stop calling tools when the task is not actually complete.\n",
    "-  Prolonged Looping: The agent is never satisfied with the state of its information.\n",
    "\n",
    "The first failure mode results in the agent collecting insufficient information. In the deep research context, the answer may end up being too shallow. The second failure mode results in the agent utilizing an excessive number of tokens. In the deep research context, irrelevant information may poison the result.\n",
    "\n",
    "We tuned our prompt to avoid these problems. But, let's set up a toy eval dataset that allows us to easily test agent decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage, HumanMessage\n",
    "\n",
    "# Scenario 1: Agent should CONTINUE - has insufficient/irrelevant information + think_tool realizes more research needed\n",
    "messages_should_continue = [\n",
    "    HumanMessage(content=\"What are the top coffee shops in San Francisco based on coffee quality?\"),\n",
    "    AIMessage(\n",
    "        content=\"I'll search for information about top coffee shops in San Francisco focusing on coffee quality.\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"tavily_search\",\n",
    "                \"args\": {\n",
    "                    \"query\": \"coffee shops San Francisco popular locations\"\n",
    "                },\n",
    "                \"id\": \"call_continue_search_001\",\n",
    "                \"type\": \"tool_call\"\n",
    "            }\n",
    "        ]\n",
    "    ),\n",
    "    # Tavily Search provides generic cafe information - NOT focused on coffee quality\n",
    "    ToolMessage(\n",
    "        content=\"Search results show popular San Francisco cafes: Blue Bottle Coffee has great wifi and ambiance, Philz Coffee is known for custom blends and friendly service, Café Reveille has multiple locations with good pastries and laptop-friendly spaces. Ritual Coffee offers cozy seating and is popular with students.\",\n",
    "        tool_call_id=\"call_continue_search_001\",\n",
    "    ),\n",
    "    # Agent uses think_tool to reflect and realizes the search results are insufficient\n",
    "    AIMessage(\n",
    "        content=\"Let me use the think_tool to analyze these search results and determine next steps.\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"think_tool\",\n",
    "                \"args\": {\n",
    "                    \"reflection\": \"Analysis of search results: The information I found focuses on general cafe features like wifi, ambiance, custom blends, and seating - but lacks specific coffee quality metrics. The user specifically asked for evaluation based on coffee quality, which would require expert reviews, professional ratings, specialty certifications, or quality-focused customer feedback. I need to search specifically for coffee quality assessments, Coffee Review scores, specialty coffee credentials, or expert evaluations of SF coffee shops. The current information is insufficient to answer the user's question about coffee quality.\"\n",
    "                },\n",
    "                \"id\": \"call_continue_think_001\",\n",
    "                \"type\": \"tool_call\"\n",
    "            }\n",
    "        ]\n",
    "    ),\n",
    "    # think_tool response identifies the gap and need for more targeted research\n",
    "    ToolMessage(\n",
    "        content=\"Reflection recorded: Analysis of search results: The information I found focuses on general cafe features like wifi, ambiance, custom blends, and seating - but lacks specific coffee quality metrics. The user specifically asked for evaluation based on coffee quality, which would require expert reviews, professional ratings, specialty certifications, or quality-focused customer feedback. I need to search specifically for coffee quality assessments, Coffee Review scores, specialty coffee credentials, or expert evaluations of SF coffee shops. The current information is insufficient to answer the user's question about coffee quality.\",\n",
    "        tool_call_id=\"call_continue_think_001\",\n",
    "    )\n",
    "]\n",
    "\n",
    "# Scenario 2: Agent should STOP - has comprehensive coffee quality information + think_tool reflection\n",
    "messages_should_stop = [\n",
    "    HumanMessage(content=\"What are the top coffee shops in San Francisco based on coffee quality?\"),\n",
    "    AIMessage(\n",
    "        content=\"I'll research San Francisco coffee shops specifically focusing on coffee quality assessments and expert reviews.\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"tavily_search\",\n",
    "                \"args\": {\n",
    "                    \"query\": \"best coffee quality San Francisco specialty coffee expert reviews Coffee Review ratings 2024\"\n",
    "                },\n",
    "                \"id\": \"call_stop_search_001\", \n",
    "                \"type\": \"tool_call\"\n",
    "            }\n",
    "        ]\n",
    "    ),\n",
    "    # This ToolMessage provides COMPREHENSIVE coffee quality information - sufficient to answer the question\n",
    "    ToolMessage(\n",
    "        content=\"\"\"Coffee quality research for San Francisco reveals top establishments based on expert reviews and specialty coffee credentials:\n",
    "\n",
    "**Top Quality-Focused Coffee Shops:**\n",
    "1. **Sightglass Coffee** - Coffee Review score 94/100, known for single-origin beans and precise roasting techniques. Featured in Bon Appétit's \"Best Coffee in America\" list for exceptional coffee quality.\n",
    "\n",
    "2. **Saint Frank Coffee** - Ranked #3 coffee shop in America by The Daily Meal based on coffee quality. 4.3/5 Yelp rating with reviews specifically praising \"exceptional bean quality\" and \"perfect extraction.\"\n",
    "\n",
    "3. **Ritual Coffee Roasters** - Specialty Coffee Association member, direct trade relationships, consistently rated 4.4/5 on Google with reviews highlighting \"superior coffee taste\" and \"expert barista skills.\"\n",
    "\n",
    "4. **Blue Bottle Coffee** - Third-wave coffee pioneer, Coffee Review scores averaging 90+/100, known for rigorous quality control and fresh roasting practices.\n",
    "\n",
    "5. **Four Barrel Coffee** - Local roaster with Coffee Review scores 88-92/100, praised by industry experts for \"exceptional coffee quality\" and innovative brewing methods.\n",
    "\n",
    "**Quality Indicators Found:**\n",
    "- Coffee Review professional scores (88-94/100 range)\n",
    "- Specialty Coffee Association certifications\n",
    "- Direct trade/single-origin sourcing\n",
    "- Expert recognition from food publications\n",
    "- Customer reviews specifically mentioning coffee taste and quality\n",
    "\n",
    "This provides a comprehensive assessment of SF coffee shops based specifically on coffee quality rather than ambiance or service.\"\"\",\n",
    "        tool_call_id=\"call_stop_search_001\",\n",
    "    ),\n",
    "    # Agent now uses think_tool to reflect on the search results\n",
    "    AIMessage(\n",
    "        content=\"Let me reflect on the search results using the think_tool to assess whether I have sufficient information.\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"think_tool\",\n",
    "                \"args\": {\n",
    "                    \"reflection\": \"Analysis of search results: I found comprehensive coffee quality information for SF coffee shops including: 1) Professional Coffee Review scores (88-94/100), 2) Expert rankings from reputable publications, 3) Specialty Coffee Association certifications, 4) Specific quality indicators (single-origin, roasting techniques, extraction methods), 5) Five top-rated establishments with detailed quality assessments. This covers all aspects requested: expert reviews, customer ratings, specialty certifications. I have enough information to provide a well-supported ranking based specifically on coffee quality. No additional searches needed - I should provide my comprehensive answer now.\"\n",
    "                },\n",
    "                \"id\": \"call_think_001\",\n",
    "                \"type\": \"tool_call\"\n",
    "            }\n",
    "        ]\n",
    "    ),\n",
    "    # think_tool response confirming reflection was recorded\n",
    "    ToolMessage(\n",
    "        content=\"Reflection recorded: Analysis of search results: I found comprehensive coffee quality information for SF coffee shops including: 1) Professional Coffee Review scores (88-94/100), 2) Expert rankings from reputable publications, 3) Specialty Coffee Association certifications, 4) Specific quality indicators (single-origin, roasting techniques, extraction methods), 5) Five top-rated establishments with detailed quality assessments. This covers all aspects requested: expert reviews, customer ratings, specialty certifications. I have enough information to provide a well-supported ranking based specifically on coffee quality. No additional searches needed - I should provide my comprehensive answer now.\",\n",
    "        tool_call_id=\"call_think_001\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1d6e5",
   "metadata": {},
   "source": [
    "We'll create a dataset here that has one example that should continue researching, and another example that should have all of the information necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1037dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langsmith import Client\n",
    "\n",
    "langsmith_client = Client(api_key=os.getenv(\"LANGSMITH_API_KEY\"))\n",
    "# Create the dataset\n",
    "dataset_name = \"deep_research_agent_termination\"\n",
    "if not langsmith_client.has_dataset(dataset_name=dataset_name):\n",
    "    # Create the dataset\n",
    "    dataset = langsmith_client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"A dataset that evaluates whether a researcher can accurately decide to continue calling tools, or to stop.\",\n",
    "    )\n",
    "\n",
    "    # Create the examples\n",
    "    langsmith_client.create_examples(\n",
    "        dataset_id=dataset.id,\n",
    "        examples=[\n",
    "            {\n",
    "                \"inputs\": {\"researcher_messages\": messages_should_continue},\n",
    "                \"outputs\": {\"next_step\": \"continue\"},\n",
    "            },\n",
    "            {\n",
    "                \"inputs\": {\"researcher_messages\": messages_should_stop},\n",
    "                \"outputs\": {\"next_step\": \"stop\"},\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529cd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def evaluate_next_step(outputs: dict, reference_outputs:dict):\n",
    "    tool_calls = outputs[\"researcher_messages\"][-1].tool_calls\n",
    "    made_tool_call = len(tool_calls) > 0\n",
    "    return {\n",
    "        \"key\": \"correct_next_step\",\n",
    "        \"score\": made_tool_call == (reference_outputs[\"next_step\"] == \"continue\")\n",
    "    }\n",
    "\n",
    "def target_func(inputs: dict):\n",
    "    config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "    result = researcher_agent.nodes[\"llm_call\"].invoke(inputs, config=config)\n",
    "    return result\n",
    "\n",
    "langsmith_client.evaluate(\n",
    "    target_func,\n",
    "    data=dataset_name,\n",
    "    evaluators=[evaluate_next_step],\n",
    "    experiment_prefix=\"Researcher Iteration\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7aa53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
