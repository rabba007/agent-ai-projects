{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2cb9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2578c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM for use with router / structured output\n",
    "from langchain.chat_models import init_chat_model\n",
    "model_gemini_flash = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", timeout=30, temperature=0)\n",
    "model_llama_groq = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\", timeout=30, temperature=0)\n",
    "model_gpt_4o_mini = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", timeout=30, temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ClassificationResult(BaseModel):\n",
    "  result:Literal[\"TOXIC\",\"NON_TOXIC\"] = Field(\"llm's classification result if the user input text is 'TOXIC' or 'NON_TOXIC'\")\n",
    "\n",
    "@traceable\n",
    "def toxicity_classifier(input:dict)->dict:\n",
    "    instructions = (\n",
    "      \"Please review the user query below and determine if it contains any form of toxic behavior, \"\n",
    "      \"such as insults, threats, or highly negative comments. Respond with 'TOXIC' if it does \"\n",
    "      \"and 'NOT_TOXIC' if it doesn't.\"\n",
    "    )\n",
    "    classification_result = model_llama_groq.with_structured_output(ClassificationResult).invoke([SystemMessage(instructions), HumanMessage(input[\"text\"])])\n",
    "\n",
    "    return {\"class\":classification_result.result}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "747946a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='TOXIC' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 90, 'total_tokens': 94, 'completion_time': 0.010150632, 'completion_tokens_details': None, 'prompt_time': 0.007598481, 'prompt_tokens_details': None, 'queue_time': 0.051507409, 'total_time': 0.017749113}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b9718-b691-7da0-860f-b41b644c3807-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 90, 'output_tokens': 4, 'total_tokens': 94}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class': 'TOXIC'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_classifier({\"text\": \"Shut up, idiot\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db6b9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "ls_client = Client()\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"inputs\": {\"text\": \"Shut up, idiot\"},\n",
    "    \"outputs\": {\"label\": \"TOXIC\"},\n",
    "  },\n",
    "  {\n",
    "    \"inputs\": {\"text\": \"You're a wonderful person\"},\n",
    "    \"outputs\": {\"label\": \"NOT_TOXIC\"},\n",
    "  },\n",
    "  {\n",
    "    \"inputs\": {\"text\": \"This is the worst thing ever\"},\n",
    "    \"outputs\": {\"label\": \"TOXIC\"},\n",
    "  },\n",
    "  {\n",
    "    \"inputs\": {\"text\": \"I had a great day today\"},\n",
    "    \"outputs\": {\"label\": \"NOT_TOXIC\"},\n",
    "  },\n",
    "  {\n",
    "    \"inputs\": {\"text\": \"Nobody likes you\"},\n",
    "    \"outputs\": {\"label\": \"TOXIC\"},\n",
    "  },\n",
    "  {\n",
    "    \"inputs\": {\"text\": \"This is unacceptable. I want to speak to the manager.\"},\n",
    "    \"outputs\": {\"label\": \"NOT_TOXIC\"},\n",
    "  },\n",
    "]\n",
    "\n",
    "dataset_name=\"Toxic Queries\"\n",
    "if not ls_client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = ls_client.create_dataset(dataset_name=dataset_name)\n",
    "    ls_client.create_examples(\n",
    "        dataset_id=dataset.id,\n",
    "        examples=examples,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd8656aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(inputs:dict, outputs:dict, reference_outputs:dict)->bool:\n",
    "    return outputs[\"class\"] == reference_outputs[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94b2f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'llama-3.1-8b-instant, groq-2fb1b244' at:\n",
      "https://smith.langchain.com/o/469b91a8-b891-4cd4-b99e-a7ed78ed0542/datasets/8759ad99-ea4b-494e-bffb-e75537a9542a/compare?selectedSessions=fe69b632-fab9-4e51-9845-1dfa0840b82a\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='NOT_TOXIC' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 91, 'total_tokens': 96, 'completion_time': 0.004340536, 'completion_tokens_details': None, 'prompt_time': 0.005066113, 'prompt_tokens_details': None, 'queue_time': 0.050370957, 'total_time': 0.009406649}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b971b-6bd6-7301-95bc-3dfaf0c56dba-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 91, 'output_tokens': 5, 'total_tokens': 96}\n",
      "content='TOXIC' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 88, 'total_tokens': 92, 'completion_time': 0.013816143, 'completion_tokens_details': None, 'prompt_time': 0.005054011, 'prompt_tokens_details': None, 'queue_time': 0.061743959, 'total_time': 0.018870154}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b971b-6bd4-7db1-9e91-6486218912c8-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 88, 'output_tokens': 4, 'total_tokens': 92}\n",
      "content='TOXIC' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 90, 'total_tokens': 94, 'completion_time': 0.009288434, 'completion_tokens_details': None, 'prompt_time': 0.005921389, 'prompt_tokens_details': None, 'queue_time': 0.055775261, 'total_time': 0.015209823}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b971b-6bda-7d50-9b2f-ab89bcfb16a4-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 90, 'output_tokens': 4, 'total_tokens': 94}\n",
      "content='NOT_TOXIC\\n\\nThis query appears to be a complaint or a request for assistance, which is a normal and non-toxic expression of frustration. The language used is direct but not aggressive or insulting.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 97, 'total_tokens': 139, 'completion_time': 0.074058016, 'completion_tokens_details': None, 'prompt_time': 0.005408048, 'prompt_tokens_details': None, 'queue_time': 0.050403072, 'total_time': 0.079466064}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b971b-6bd9-71d0-a4a4-5f146e35f77d-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 97, 'output_tokens': 42, 'total_tokens': 139}\n",
      "content='NOT_TOXIC' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 91, 'total_tokens': 96, 'completion_time': 0.004809089, 'completion_tokens_details': None, 'prompt_time': 0.006842789, 'prompt_tokens_details': None, 'queue_time': 0.051600711, 'total_time': 0.011651878}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b971b-6ced-78a1-b360-a16fa3312e18-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 91, 'output_tokens': 5, 'total_tokens': 96}\n",
      "content='NOT_TOXIC' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 90, 'total_tokens': 95, 'completion_time': 0.004691042, 'completion_tokens_details': None, 'prompt_time': 0.007820104, 'prompt_tokens_details': None, 'queue_time': 0.057024125, 'total_time': 0.012511146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b971b-6cf1-7bf1-8158-6db02225da29-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 90, 'output_tokens': 5, 'total_tokens': 95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:01,  5.93it/s]\n"
     ]
    }
   ],
   "source": [
    "results = ls_client.evaluate(\n",
    "    toxicity_classifier,\n",
    "    data=dataset.name,\n",
    "    evaluators=[correct],\n",
    "    experiment_prefix=\"llama-3.1-8b-instant, groq\",  # optional, experiment name prefix\n",
    "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
    "    max_concurrency=4,  # optional, add concurrency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3a98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
